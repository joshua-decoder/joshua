# This file is a template for the Joshua pipeline; variables enclosed
# in <angle-brackets> are substituted by the pipeline script as
# appropriate.  This file also serves to document Joshua's many
# parameters.

# This is the grammar file and the grammar file format.  The grammar
# file can be compressed with gzip.  Supported formats are "thrax" and
# "samt".  The latter denotes the format used in Zollmann and
# Venugopal's SAMT decoder (http://www.cs.cmu.edu/~zollmann/samt/).

tm-file = <GRAMMAR_FILE>
tm-format = thrax

# The span limit is the maximum input span permitted for the
# application of grammar rules found in the grammar file.

span-limit = 12

# This symbol is used over unknown words in the source language

default-non-terminal = <OOV>

# This is the goal nonterminal, used to determine when a complete
# parse is found.  It should correspond to the root-level rules in the
# glue grammar.

goal-symbol = GOAL

# If set to true (true is denoted with a case-insensitive form of the
# word "true"), the decoder will look for sentence-specific grammars
# by appending the sentence ID to the value of {tm_file}.  e.g., if
# tm_file=grammar, it will look for grammar.19 when decoding sentence
# 19.  Sentence numbers are placed before compression suffixes, so if
# tm_file=grammar.gz, Joshua will look for grammar.19.gz.

use-sent-specific-tm = false

# The glue grammar contains glue rules.  Its main distinction from the
# regular grammar is that the span limit does not apply to it.  In the
# future, the explicit distinction between these grammars will be
# dropped in favor of specifying an arbitrary number of grammars with
# various per-grammar settings.

glue-file = <GLUE_GRAMMAR>
glue-format = thrax

# Language model config.

# Multiple language models are supported.  For each language model,
# create a line in the following format, 
#
# lm = TYPE 5 false false 100 FILE
#
# where the six fields correspond to the following values:
# - LM type: one of "kenlm", "berkeleylm", "javalm" (not recommended), or "none"
# - LM order: the N of the N-gram language model
# - whether to use left equivalent state (currently not supported)
# - whether to use right equivalent state (currently not supported)
# - the ceiling cost of any n-gram (currently ignored)
# - LM file: the location of the language model file
# You also need to add a weight for each language model below.

<LMLINES>

# The suffix _OOV is appended to unknown source-language words if this
# is set to true.

mark-oovs = false

# The pop-limit for decoding.  This determines how many hypotheses are
# considered over each span of the input.

pop-limit = 100

# How many hypotheses to output

top-n = 300

# Whether those hypotheses should be distinct strings

use-unique-nbest = true

# The following two options control whether to output (a) the
# derivation tree and (b) word alignment information (for each
# hypothesis on the n-best list).  Note that setting these options to
# 'true' will currently break MERT, so don't use these in the
# pipeline.

use-tree-nbest = false
include-align-index = false

## Model weights #####################################################

# For each langage model line listed above, create a weight in the
# following format: the keyword "lm", a 0-based index, and the weight.
# lm INDEX WEIGHT

<LMWEIGHTS>

# The phrasal weights correspond to weights stored with each of the
# grammar rules.  The format is
#
#   phrasemodel owner COLUMN WEIGHT
#
# where COLUMN denotes the 0-based order of the parameter in the
# grammar file and WEIGHT is the corresponding weight.  In the future,
# we plan to add a sparse feature representation which will simplify
# this.

phrasemodel pt 0 1.0
phrasemodel pt 1 1.0
phrasemodel pt 2 1.0
phrasemodel pt 3 1.0
phrasemodel pt 4 1.0
phrasemodel pt 5 1.0
phrasemodel pt 6 1.0
phrasemodel pt 7 1.0
phrasemodel pt 8 1.0
phrasemodel pt 9 1.0
phrasemodel pt 10 1.0
phrasemodel pt 11 1.0
phrasemodel pt 12 1.0
phrasemodel pt 13 1.0
phrasemodel pt 14 1.0
phrasemodel pt 15 1.0
phrasemodel pt 16 1.0

# The wordpenalty feature counts the number of words in each hypothesis.

wordpenalty -1.0

# This feature counts the number of unknown words in the hypothesis.

oovpenalty -100
